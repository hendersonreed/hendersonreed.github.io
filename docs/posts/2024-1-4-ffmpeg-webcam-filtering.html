<!DOCTYPE html>
<html>
  <head>
    <link rel="stylesheet" type="text/css" href="/style.css">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <!-- gotta complete this sometime in the future, but for now we'll eliminate it -->
    <!-- and live without images in link previews. pretty sure that some sort of post-processing -->
    <!-- will be necessary, that analyzes the page contents to identify what the title/url/image should be -->
    <!-- and then substitutes a placeholder for that content. -->
    <!-- opengraph meta tags -->
    <!-- <meta property="og:title" content="henderson's log"> -->
    <!-- <meta property="og:description" content="The website of Henderson Reed Hummel"> -->
    <!-- <meta property="og:image" content="https://hendersonreed.github.io/android-chrome-192x192.png"> -->
    <!-- <meta property="og:url" content="https://hendersonreed.github.io/"> -->
    <!-- <meta property="og:type" content="website"> -->
    <!-- Twitter meta tags -->
    <!-- <meta name="twitter:card" content="https://hendersonreed.github.io/android-chrome-192x192.png"> -->
    <!-- <meta name="twitter:title" content="henderson's log"> -->
    <!-- <meta name="twitter:description" content="The website of Henderson Reed Hummel"> -->
    <!-- <meta name="twitter:image" content="https://hendersonreed.github.io/android-chrome-192x192.png"> -->

    <!-- magic favicon stuff -->
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">

    <title>henderson's log: Using ffmpeg for weird video effects</title>
  </head>

  <body>

    <br>
    <h1 class="title center"><a href="/">henderson reed hummel<a></h1>

    <div class="topnav center">
      <h3>
	<a href="/pages/hire.html">hire</a>
	<a href="/assets/hhummel.pdf">resume</a>
	<a href="/pages/contact.html">contact me</a>
      </h3>
    </div>
    <hr>

<h1 id="using-ffmpeg-for-weird-video-effects">Using ffmpeg for weird video effects</h1>
<p>Painfully won, maybe this <code>ffmpeg</code> incantation can help you, dear reader.</p>
<h2 id="wait-why-again-are-we-doing-this">wait, why again are we doing this?</h2>
<p>I‚Äôm working on a project at the moment that involves applying a variety of digital effects to a webcam video stream. In my preparatory research for the video effect tooling, I discovered that there‚Äôs actually a fascinatingly large number of audio/video filters for <code>ffmpeg</code>.</p>
<p>This solution appeals to me for a few reasons:</p>
<ol type="1">
<li>small-ish and simple-ish</li>
<li>CLI solution (the final result is going to be projected, so it‚Äôs nice if the effects are being applied by something that isn‚Äôt displayed on screen.)</li>
<li>straightforward to automate (can write a startup script to reset the installation in case of power loss.)</li>
</ol>
<p>This solution also frightens me because ffmpeg is arcane and obscure (relative to most tools I like to use.)</p>
<p>So, I thought I‚Äôd write up what I did and how I learned it! Primarily so that I can use it in the future for my own reference.</p>
<h2 id="to-google">to google!</h2>
<p>The google results for ‚Äústream ffmpeg webcam video stream‚Äù are mostly unsolved requests for help on stack-overflow üôÉ</p>
<p>However, there are some useful tidbits here and there.</p>
<p>First, we need to know what our device is called, according to ffmpeg. On Linux, this can be done with <code>v4l2-ctl --list-devices</code> (I had to install the <code>v4l-utils</code> package on Fedora.)</p>
<p>On my system, the default webcam is /dev/video0. So let‚Äôs test to see if we can simply record from the webcam to a file:</p>
<pre><code>ffmpeg -f v4l2 -i /dev/video0 output.mp4 </code></pre>
<p><video src="/assets/photos/blogposts/ffmpeg-filters/ffmpeg-article-video.mp4" controls=""><a href="/assets/photos/blogposts/ffmpeg-filters/ffmpeg-article-video.mp4">Video</a></video></p>
<p>I‚Äôd call that a success!</p>
<h2 id="opening-the-video-stream.">opening the video stream.</h2>
<p>The simplest thing here is to use one process to create a video stream, and another to open it. This way our capturing ffmpeg incantation isn‚Äôt <em>too</em> long.</p>
<p>To stream:</p>
<pre><code>ffmpeg -f v4l2 -i /dev/video0 \
    -framerate 25 \
    -video_size 1280x720 \
    -f mpegts udp://localhost:1234</code></pre>
<p>We can open up the stream with a simple <code>ffplay -fflags nobuffer udp://localhost:1234</code>. (<code>-fflags nobuffer</code> removes a ~10 second buffer that ffplay adds for some reason.)</p>
<h2 id="applying-weird-effects">applying weird effects!</h2>
<p>now we can review the ffmpeg documentation, specifically <a href="https://ffmpeg.org/ffmpeg-filters.html#Video-Filters">the video filters</a>.</p>
<p>Let‚Äôs try this out.</p>
<pre><code>ffmpeg -f v4l2 -i /dev/video0 \
        -framerate 25 \
        -video_size 1280x720 \
        -vf edgedetect \
        -f mpegts udp://localhost:1234</code></pre>
<p>Run <code>ffplay -fflags nobuffer udp://localhost:1234</code> again, and let‚Äôs see what the result is‚Ä¶</p>
<p>Success! We‚Äôve got edge detection working:</p>
<p><img src="/assets/photos/blogposts/ffmpeg-filters/edge-detection-filter.png" /></p>
<p><code>ffmpeg -filters</code> gives us a list of all the filters that exist in our installed copy of the utility - any that are marked <code>V-&gt;V</code> are video-to-video, and we can experiment to see what cool stuff we can find. <code>waveform</code> and <code>elbg</code> are both interesting - this is gonna be the fun part.</p>
<h2 id="bonus-round-quick-n-dirty-script">bonus round: quick-n-dirty script</h2>
<p>I want to speed up trying out new filters. It‚Äôd be very nice if I could simply type out a filter name, maybe some parameters, and hit <code>CR</code> to see the results immediately. This is all to preface the following very bad, no-good, totally incorrect, inflexible, ‚Äúworks-on-my-machine‚Äù, highly effective script (provided in large part by chatGPT.)</p>
<pre><code>#!/bin/bash

# handle termination signals and kill both processes
terminate_processes() {
    echo &quot;Terminating processes...&quot;
    kill -TERM &quot;$pid1&quot; &quot;$pid2&quot; 2&gt;/dev/null
    wait &quot;$pid1&quot; 2&gt;/dev/null
    wait &quot;$pid2&quot; 2&gt;/dev/null
    exit 0
}

# Trap termination signals
trap terminate_processes SIGINT SIGTERM

# Run the ffmpeg command to capture and stream the webcam in a terminal window and store its process ID
alacritty --command ffmpeg -f v4l2 -i /dev/video0 \
        -framerate 25 \
        -video_size 1280x720 \
        -vf &quot;$1&quot;\
        -f mpegts udp://localhost:1234 &amp;
pid1=$!

# Run the ffplay command in a terminal window and store its process ID
alacritty --command ffplay -fflags nobuffer udp://localhost:1234 &amp;
pid2=$!

# Wait for either of the commands to finish
wait -n &quot;$pid1&quot; &quot;$pid2&quot;

# If one process is terminated, kill the other one
terminate_processes</code></pre>
<p>It works perfectly for me :)</p>

    <!-- this is the start of the footer -->
    <hr>
    <a href="/sitemap.html">sitemap</a>
    <br>
    <a href="https://github.com/hendersonreed/psg">built with psg</a>
    <hr>
  </body>
</html>
